# Epic 2.6: AI Processing Pipeline

## Methodology Guidance
**SPECTRA Phase**: Implementation/AI Integration
**Approach**: Unified async pipeline for all AI operations
**Tools**: Cloudflare Queues, Workers, orchestration patterns

## Wave Context
**Wave**: 2 - AI Infrastructure + P0 Capabilities
**Priority**: Medium (ties all AI features together)
**Dependencies**: Epics 2.1-2.5 (all AI features)
**Estimated Duration**: 6 hours

## Quality Requirements
- Feedback creation response < 500ms
- Full AI processing complete within 30s
- Partial failures don't block other steps
- Processing status visible to admins

---

## Tasks

### 2.6.1 Unified Processing Flow (2h)
**Objective**: Single pipeline orchestrating all AI tasks

**Steps**:
1. Define pipeline stages:
   ```typescript
   // src/lib/ai/pipeline.ts

   export enum PipelineStage {
     EMBED = 'embed',
     CLASSIFY = 'classify',
     SENTIMENT = 'sentiment',
     URGENCY = 'urgency',
     THEME = 'theme',
     DUPLICATE = 'duplicate',
     PRIORITY = 'priority'
   }

   interface PipelineState {
     feedbackId: string;
     workspaceId: string;
     stages: Record<PipelineStage, 'pending' | 'processing' | 'completed' | 'failed'>;
     startedAt: string;
     completedAt?: string;
     errors: Record<PipelineStage, string>;
   }

   const PIPELINE_ORDER: PipelineStage[] = [
     PipelineStage.EMBED,      // Must run first (needed for others)
     PipelineStage.CLASSIFY,   // Can run in parallel after embed
     PipelineStage.SENTIMENT,  // Can run in parallel after embed
     PipelineStage.URGENCY,    // Can run in parallel after embed
     PipelineStage.DUPLICATE,  // Needs embed
     PipelineStage.THEME,      // Needs embed
     PipelineStage.PRIORITY    // Needs sentiment + urgency
   ];
   ```

2. Create pipeline orchestrator:
   ```typescript
   export async function runPipeline(
     feedbackId: string,
     workspaceId: string,
     env: Env
   ): Promise<PipelineState> {
     const state: PipelineState = {
       feedbackId,
       workspaceId,
       stages: Object.fromEntries(
         PIPELINE_ORDER.map(s => [s, 'pending'])
       ) as any,
       startedAt: new Date().toISOString(),
       errors: {} as any
     };

     // Save initial state
     await savePipelineState(feedbackId, state, env);

     try {
       // Stage 1: Embedding (required for everything else)
       await runStage(state, PipelineStage.EMBED, async () => {
         await processEmbedding(feedbackId, env);
       }, env);

       // Stage 2: Parallel processing (classification, sentiment, urgency)
       await Promise.allSettled([
         runStage(state, PipelineStage.CLASSIFY, async () => {
           await processClassification(feedbackId, env);
         }, env),
         runStage(state, PipelineStage.SENTIMENT, async () => {
           await processSentiment(feedbackId, env);
         }, env),
         runStage(state, PipelineStage.URGENCY, async () => {
           await processUrgency(feedbackId, env);
         }, env)
       ]);

       // Stage 3: Post-processing (duplicate detection, theme assignment)
       await Promise.allSettled([
         runStage(state, PipelineStage.DUPLICATE, async () => {
           const vectors = await env.VECTORIZE.getByIds([feedbackId]);
           if (vectors[0]) {
             const candidates = await findDuplicates(feedbackId, vectors[0].values, workspaceId, env);
             await storeDuplicateSuggestions(feedbackId, candidates, env);
           }
         }, env),
         runStage(state, PipelineStage.THEME, async () => {
           await processThemeAssignment(feedbackId, env);
         }, env)
       ]);

       // Stage 4: Priority calculation (needs sentiment + urgency)
       await runStage(state, PipelineStage.PRIORITY, async () => {
         await updatePriorityScore(feedbackId, env);
       }, env);

       state.completedAt = new Date().toISOString();

     } catch (error) {
       console.error('Pipeline failed:', error);
     }

     // Save final state
     await savePipelineState(feedbackId, state, env);
     return state;
   }

   async function runStage(
     state: PipelineState,
     stage: PipelineStage,
     fn: () => Promise<void>,
     env: Env
   ): Promise<void> {
     state.stages[stage] = 'processing';
     await savePipelineState(state.feedbackId, state, env);

     try {
       await fn();
       state.stages[stage] = 'completed';
     } catch (error) {
       state.stages[stage] = 'failed';
       state.errors[stage] = error instanceof Error ? error.message : 'Unknown error';
       console.error(`Stage ${stage} failed:`, error);
     }

     await savePipelineState(state.feedbackId, state, env);
   }
   ```

3. Store pipeline state:
   ```typescript
   async function savePipelineState(
     feedbackId: string,
     state: PipelineState,
     env: Env
   ): Promise<void> {
     await env.KV.put(
       `pipeline:${feedbackId}`,
       JSON.stringify(state),
       { expirationTtl: 86400 } // 24 hours
     );

     // Update feedback processing status
     const overallStatus = getOverallStatus(state);
     await env.DB.prepare(`
       UPDATE feedback_items
       SET ai_processing_status = ?, updated_at = datetime('now')
       WHERE id = ?
     `).bind(overallStatus, feedbackId).run();
   }

   function getOverallStatus(state: PipelineState): string {
     const stages = Object.values(state.stages);
     if (stages.every(s => s === 'completed')) return 'completed';
     if (stages.some(s => s === 'failed')) return 'partial';
     if (stages.some(s => s === 'processing')) return 'processing';
     return 'pending';
   }
   ```

4. Add processing status column:
   ```sql
   ALTER TABLE feedback_items ADD COLUMN ai_processing_status TEXT DEFAULT 'pending';
   -- pending, processing, completed, partial, failed
   ```

**Acceptance Criteria**:
- [ ] Pipeline runs all stages in correct order
- [ ] Parallel stages execute concurrently
- [ ] Failed stages don't block others
- [ ] State persisted and queryable
- [ ] Pipeline is idempotent (can re-run safely)

---

### 2.6.2 Background Processing (2h)
**Objective**: Non-blocking AI processing

**Steps**:
1. Queue job on feedback creation:
   ```typescript
   // In feedback creation handler
   async function createFeedback(request: Request, env: Env) {
     // ... create feedback in database ...

     // Queue AI processing (immediate return)
     await env.AI_QUEUE.send({
       type: 'process_feedback',
       feedbackId,
       workspaceId,
       timestamp: Date.now()
     });

     // Return immediately (< 100ms)
     return jsonResponse({
       id: feedbackId,
       ai_processing_status: 'pending',
       // ... other fields
     }, 201);
   }
   ```

2. Create queue consumer:
   ```typescript
   // src/workers/ai-processor.ts

   interface AIQueueMessage {
     type: 'process_feedback' | 'batch_classify' | 'recluster' | 'retry_stage';
     feedbackId?: string;
     workspaceId?: string;
     stage?: PipelineStage;
     timestamp: number;
   }

   export default {
     async queue(
       batch: MessageBatch<AIQueueMessage>,
       env: Env
     ): Promise<void> {
       for (const message of batch.messages) {
         const job = message.body;

         try {
           switch (job.type) {
             case 'process_feedback':
               await runPipeline(job.feedbackId!, job.workspaceId!, env);
               break;

             case 'retry_stage':
               await retryPipelineStage(job.feedbackId!, job.stage!, env);
               break;

             case 'batch_classify':
               await batchClassifyFeedback({
                 workspaceId: job.workspaceId!,
                 batchSize: 10,
                 dryRun: false
               }, env);
               break;

             case 'recluster':
               await runFullReclustering(job.workspaceId!, env);
               break;
           }

           message.ack();

         } catch (error) {
           console.error(`Job ${job.type} failed:`, error);

           // Retry with backoff
           const retryDelay = Math.min(300, 60 * Math.pow(2, message.attempts));
           message.retry({ delaySeconds: retryDelay });
         }
       }
     }
   };
   ```

3. Get processing status endpoint:
   ```typescript
   // GET /api/v1/feedback/:id/processing-status
   async function handleGetProcessingStatus(request: Request, env: Env) {
     const { feedbackId } = parseParams(request);

     const state = await env.KV.get(`pipeline:${feedbackId}`, 'json') as PipelineState | null;

     if (!state) {
       const feedback = await getFeedbackById(feedbackId, env);
       return jsonResponse({
         status: feedback?.ai_processing_status || 'unknown',
         stages: null
       });
     }

     return jsonResponse({
       status: getOverallStatus(state),
       stages: state.stages,
       errors: state.errors,
       started_at: state.startedAt,
       completed_at: state.completedAt,
       duration_ms: state.completedAt
         ? new Date(state.completedAt).getTime() - new Date(state.startedAt).getTime()
         : null
     });
   }
   ```

4. WebSocket for real-time updates (optional):
   ```typescript
   // Using Durable Objects for WebSocket
   export class FeedbackProcessingDO {
     private sessions: Set<WebSocket> = new Set();

     async fetch(request: Request): Promise<Response> {
       const [client, server] = Object.values(new WebSocketPair());

       server.accept();
       this.sessions.add(server);

       server.addEventListener('close', () => {
         this.sessions.delete(server);
       });

       return new Response(null, { status: 101, webSocket: client });
     }

     async notifyProgress(feedbackId: string, stage: string, status: string): Promise<void> {
       const message = JSON.stringify({ feedbackId, stage, status });
       for (const session of this.sessions) {
         session.send(message);
       }
     }
   }
   ```

**Acceptance Criteria**:
- [ ] Feedback creation returns < 500ms
- [ ] AI processing runs in background
- [ ] Status queryable via API
- [ ] Processing completes within 30 seconds

---

### 2.6.3 Retry & Error Handling (1h)
**Objective**: Robust error recovery

**Steps**:
1. Implement stage-level retry:
   ```typescript
   // src/lib/ai/retry.ts

   export async function retryPipelineStage(
     feedbackId: string,
     stage: PipelineStage,
     env: Env
   ): Promise<boolean> {
     const state = await env.KV.get(`pipeline:${feedbackId}`, 'json') as PipelineState | null;

     if (!state || state.stages[stage] !== 'failed') {
       return false;
     }

     const processors: Record<PipelineStage, () => Promise<void>> = {
       [PipelineStage.EMBED]: () => processEmbedding(feedbackId, env),
       [PipelineStage.CLASSIFY]: () => processClassification(feedbackId, env),
       [PipelineStage.SENTIMENT]: () => processSentiment(feedbackId, env),
       [PipelineStage.URGENCY]: () => processUrgency(feedbackId, env),
       [PipelineStage.DUPLICATE]: async () => {
         const vectors = await env.VECTORIZE.getByIds([feedbackId]);
         if (vectors[0]) {
           await findDuplicates(feedbackId, vectors[0].values, state.workspaceId, env);
         }
       },
       [PipelineStage.THEME]: () => processThemeAssignment(feedbackId, env),
       [PipelineStage.PRIORITY]: () => updatePriorityScore(feedbackId, env)
     };

     try {
       await processors[stage]();
       state.stages[stage] = 'completed';
       delete state.errors[stage];
       await savePipelineState(feedbackId, state, env);
       return true;
     } catch (error) {
       state.errors[stage] = error instanceof Error ? error.message : 'Retry failed';
       await savePipelineState(feedbackId, state, env);
       return false;
     }
   }
   ```

2. Dead letter queue handling:
   ```typescript
   // src/workers/ai-dlq-processor.ts

   export default {
     async queue(
       batch: MessageBatch<AIQueueMessage>,
       env: Env
     ): Promise<void> {
       for (const message of batch.messages) {
         const job = message.body;

         // Log failed job for manual review
         await env.DB.prepare(`
           INSERT INTO failed_ai_jobs (id, type, feedback_id, workspace_id, error, created_at)
           VALUES (?, ?, ?, ?, ?, datetime('now'))
         `).bind(
           generateId('fail'),
           job.type,
           job.feedbackId || null,
           job.workspaceId || null,
           'Max retries exceeded'
         ).run();

         // Notify admins (via webhook or email)
         if (job.workspaceId) {
           await notifyWorkspaceAdmins(job.workspaceId, {
             type: 'ai_processing_failed',
             feedbackId: job.feedbackId,
             jobType: job.type
           }, env);
         }

         message.ack();
       }
     }
   };
   ```

3. Create failed jobs table:
   ```sql
   CREATE TABLE failed_ai_jobs (
     id TEXT PRIMARY KEY,
     type TEXT NOT NULL,
     feedback_id TEXT,
     workspace_id TEXT,
     error TEXT,
     resolved_at TEXT,
     resolved_by TEXT,
     created_at TEXT DEFAULT (datetime('now'))
   );
   ```

4. Admin retry endpoint:
   ```typescript
   // POST /api/v1/feedback/:id/retry-processing
   async function handleRetryProcessing(request: Request, env: Env) {
     const { feedbackId } = parseParams(request);
     const { stages } = await validateBody(request, z.object({
       stages: z.array(z.nativeEnum(PipelineStage)).optional()
     }));

     const feedback = await getFeedbackById(feedbackId, env);
     if (!feedback) return errorResponse('NOT_FOUND', 'Feedback not found', 404);

     await requirePermission(request, env, feedback.workspace_id, 'feedback:moderate');

     if (stages?.length) {
       // Retry specific stages
       const results: Record<string, boolean> = {};
       for (const stage of stages) {
         results[stage] = await retryPipelineStage(feedbackId, stage, env);
       }
       return jsonResponse({ retried: results });
     } else {
       // Re-run full pipeline
       await env.AI_QUEUE.send({
         type: 'process_feedback',
         feedbackId,
         workspaceId: feedback.workspace_id,
         timestamp: Date.now()
       });
       return jsonResponse({ message: 'Pipeline re-queued' });
     }
   }
   ```

**Acceptance Criteria**:
- [ ] Individual stages can be retried
- [ ] Dead letter queue captures permanent failures
- [ ] Admins notified of failures
- [ ] Failed jobs logged for review
- [ ] Retry endpoint works

---

### 2.6.4 AI Processing Dashboard (1h)
**Objective**: Visibility into AI system health

**Steps**:
1. Processing metrics endpoint:
   ```typescript
   // GET /api/v1/workspaces/:id/ai/metrics
   async function handleGetAIMetrics(request: Request, env: Env) {
     const { workspaceId } = parseParams(request);
     await requirePermission(request, env, workspaceId, 'analytics:view');

     // Processing status distribution
     const statusDist = await env.DB.prepare(`
       SELECT ai_processing_status, COUNT(*) as count
       FROM feedback_items fi
       JOIN boards b ON fi.board_id = b.id
       WHERE b.workspace_id = ?
       GROUP BY ai_processing_status
     `).bind(workspaceId).all();

     // Processing times (from KV states)
     const recentStates = await getRecentPipelineStates(workspaceId, 100, env);
     const avgProcessingTime = recentStates.length > 0
       ? recentStates
           .filter(s => s.completedAt)
           .reduce((sum, s) =>
             sum + (new Date(s.completedAt!).getTime() - new Date(s.startedAt).getTime()), 0
           ) / recentStates.filter(s => s.completedAt).length
       : null;

     // Failed jobs count
     const failedJobs = await env.DB.prepare(`
       SELECT COUNT(*) as count
       FROM failed_ai_jobs
       WHERE workspace_id = ? AND resolved_at IS NULL
     `).bind(workspaceId).first();

     // Usage stats (last 30 days)
     const usage = await getMonthlyUsage(workspaceId, env);

     return jsonResponse({
       status_distribution: Object.fromEntries(
         statusDist.results.map(r => [r.ai_processing_status, r.count])
       ),
       avg_processing_time_ms: avgProcessingTime,
       failed_jobs_pending: failedJobs?.count || 0,
       usage_last_30_days: usage,
       queue_health: await getQueueHealth(env)
     });
   }
   ```

2. Failed items list:
   ```typescript
   // GET /api/v1/workspaces/:id/ai/failed-items
   async function handleGetFailedItems(request: Request, env: Env) {
     const { workspaceId } = parseParams(request);
     await requirePermission(request, env, workspaceId, 'feedback:moderate');

     const url = new URL(request.url);
     const limit = Math.min(parseInt(url.searchParams.get('limit') || '20'), 100);

     // Get failed processing items
     const failed = await env.DB.prepare(`
       SELECT fi.id, fi.title, fi.ai_processing_status, fi.updated_at
       FROM feedback_items fi
       JOIN boards b ON fi.board_id = b.id
       WHERE b.workspace_id = ? AND fi.ai_processing_status IN ('failed', 'partial')
       ORDER BY fi.updated_at DESC
       LIMIT ?
     `).bind(workspaceId, limit).all();

     // Enrich with pipeline states
     const enriched = await Promise.all(
       failed.results.map(async (item) => {
         const state = await env.KV.get(`pipeline:${item.id}`, 'json') as PipelineState | null;
         return {
           ...item,
           failed_stages: state
             ? Object.entries(state.stages)
                 .filter(([_, status]) => status === 'failed')
                 .map(([stage, _]) => ({
                   stage,
                   error: state.errors[stage as PipelineStage]
                 }))
             : []
         };
       })
     );

     return jsonResponse({ items: enriched });
   }
   ```

3. Bulk retry endpoint:
   ```typescript
   // POST /api/v1/workspaces/:id/ai/retry-failed
   async function handleBulkRetryFailed(request: Request, env: Env) {
     const { workspaceId } = parseParams(request);
     await requirePermission(request, env, workspaceId, 'workspace:settings');

     // Get all failed items
     const failed = await env.DB.prepare(`
       SELECT fi.id
       FROM feedback_items fi
       JOIN boards b ON fi.board_id = b.id
       WHERE b.workspace_id = ? AND fi.ai_processing_status IN ('failed', 'partial')
       LIMIT 100
     `).bind(workspaceId).all();

     // Queue retries
     for (const item of failed.results) {
       await env.AI_QUEUE.send({
         type: 'process_feedback',
         feedbackId: item.id as string,
         workspaceId,
         timestamp: Date.now()
       });
     }

     return jsonResponse({
       queued: failed.results.length,
       message: `Queued ${failed.results.length} items for reprocessing`
     });
   }
   ```

**Acceptance Criteria**:
- [ ] Processing status distribution visible
- [ ] Average processing time tracked
- [ ] Failed items listable with errors
- [ ] Retry button for individual items
- [ ] Bulk retry for all failed

---

## Definition of Done
- [ ] Unified pipeline orchestrating all AI stages
- [ ] Background processing < 30 seconds
- [ ] Feedback creation response < 500ms
- [ ] Failed stages retryable individually
- [ ] Dashboard shows AI system health
- [ ] Dead letter handling for permanent failures

## Technical Notes
- Queue batch size: 10 (balance throughput vs memory)
- Pipeline state TTL: 24 hours in KV
- Consider Durable Objects for long-running pipelines
- Monitor queue depth for capacity planning

## Related Files
- `src/lib/ai/pipeline.ts` - Pipeline orchestrator
- `src/workers/ai-processor.ts` - Queue consumer
- `src/workers/ai-dlq-processor.ts` - Dead letter handler
- `src/routes/ai-admin.ts` - Admin endpoints
