# Epic 2.2: Semantic Deduplication

## Methodology Guidance
**SPECTRA Phase**: Implementation/AI Feature
**Approach**: Detect duplicate feedback using vector similarity
**Tools**: Cloudflare Vectorize, Workers AI embeddings

## Wave Context
**Wave**: 2 - AI Infrastructure + P0 Capabilities
**Priority**: P0 (core differentiator)
**Dependencies**: Epic 2.1 (AI infrastructure)
**Estimated Duration**: 8 hours

## Quality Requirements
- Duplicates detected within 2 seconds of creation
- 0.85 cosine similarity threshold for high-confidence matches
- No false positives flagged as duplicates
- Merge preserves all votes and comments

---

## Tasks

### 2.2.1 Embedding on Feedback Creation (1.5h)
**Objective**: Generate and store embeddings for all new feedback

**Steps**:
1. Hook into feedback creation flow:
   ```typescript
   // src/routes/feedback.ts - modify createFeedback

   async function createFeedback(request: Request, env: Env) {
     // ... existing validation and creation ...

     const feedbackId = generateId('fb');

     // Create feedback in database
     await env.DB.prepare(`
       INSERT INTO feedback_items (id, board_id, user_id, title, description, ...)
       VALUES (?, ?, ?, ?, ?, ...)
     `).bind(feedbackId, boardId, userId, title, description).run();

     // Queue AI processing (non-blocking)
     await enqueueAIJob(env.AI_QUEUE, feedbackId, workspaceId, [
       'embed', 'classify', 'sentiment'
     ]);

     return jsonResponse({ id: feedbackId, ... }, 201);
   }
   ```

2. Create embedding processor:
   ```typescript
   // src/lib/ai/processors/embed.ts

   export async function processEmbedding(
     feedbackId: string,
     env: Env
   ): Promise<void> {
     const feedback = await getFeedbackById(feedbackId, env);
     if (!feedback) throw new Error('Feedback not found');

     // Generate embedding from title + description
     const text = `${feedback.title} ${feedback.description || ''}`;
     const embedding = await generateEmbedding(env.AI, text);

     // Store in Vectorize with metadata
     await upsertVector(env.VECTORIZE, feedbackId, embedding, {
       feedback_id: feedbackId,
       board_id: feedback.board_id,
       workspace_id: feedback.workspace_id,
       created_at: feedback.created_at
     });

     // Mark as embedded
     await env.DB.prepare(`
       UPDATE feedback_items SET ai_embedding_id = ?, updated_at = datetime('now')
       WHERE id = ?
     `).bind(feedbackId, feedbackId).run();

     // Track usage
     await incrementUsage(env.DB, feedback.workspace_id, 'embeddings');
   }
   ```

3. Add embedding_id column to feedback_items:
   ```sql
   ALTER TABLE feedback_items ADD COLUMN ai_embedding_id TEXT;
   ```

**Acceptance Criteria**:
- [ ] All new feedback gets embedded asynchronously
- [ ] Embedding stored in Vectorize with metadata
- [ ] feedback_items.ai_embedding_id populated
- [ ] Usage tracked per workspace

---

### 2.2.2 Duplicate Detection (2h)
**Objective**: Find semantically similar feedback on creation

**Steps**:
1. Create duplicate detection function:
   ```typescript
   // src/lib/ai/deduplication.ts

   interface DuplicateCandidate {
     feedbackId: string;
     score: number;
     title: string;
     status: string;
   }

   const DUPLICATE_THRESHOLD = 0.85;
   const SIMILAR_THRESHOLD = 0.70;

   export async function findDuplicates(
     feedbackId: string,
     embedding: number[],
     workspaceId: string,
     env: Env
   ): Promise<DuplicateCandidate[]> {
     // Query similar vectors in same workspace
     const results = await queryVectors(env.VECTORIZE, embedding, {
       topK: 10,
       filter: { workspace_id: workspaceId }
     });

     // Filter out self and low scores
     const candidates = results.matches
       .filter(m => m.id !== feedbackId && m.score >= SIMILAR_THRESHOLD)
       .slice(0, 5);

     // Enrich with feedback details
     const enriched: DuplicateCandidate[] = [];
     for (const match of candidates) {
       const feedback = await getFeedbackById(match.id, env);
       if (feedback && !feedback.is_hidden) {
         enriched.push({
           feedbackId: match.id,
           score: match.score,
           title: feedback.title,
           status: feedback.status
         });
       }
     }

     return enriched;
   }
   ```

2. Create duplicate suggestions table:
   ```sql
   CREATE TABLE duplicate_suggestions (
     id TEXT PRIMARY KEY,
     source_feedback_id TEXT NOT NULL,
     target_feedback_id TEXT NOT NULL,
     similarity_score REAL NOT NULL,
     status TEXT DEFAULT 'pending',  -- pending, merged, dismissed
     reviewed_by TEXT,
     reviewed_at TEXT,
     created_at TEXT DEFAULT (datetime('now')),
     FOREIGN KEY (source_feedback_id) REFERENCES feedback_items(id),
     FOREIGN KEY (target_feedback_id) REFERENCES feedback_items(id),
     UNIQUE(source_feedback_id, target_feedback_id)
   );

   CREATE INDEX idx_duplicates_source ON duplicate_suggestions(source_feedback_id, status);
   CREATE INDEX idx_duplicates_pending ON duplicate_suggestions(status) WHERE status = 'pending';
   ```

3. Store suggestions after detection:
   ```typescript
   export async function storeDuplicateSuggestions(
     sourceId: string,
     candidates: DuplicateCandidate[],
     env: Env
   ): Promise<void> {
     const highConfidence = candidates.filter(c => c.score >= DUPLICATE_THRESHOLD);

     for (const candidate of highConfidence) {
       await env.DB.prepare(`
         INSERT OR IGNORE INTO duplicate_suggestions
           (id, source_feedback_id, target_feedback_id, similarity_score)
         VALUES (?, ?, ?, ?)
       `).bind(
         generateId('dup'),
         sourceId,
         candidate.feedbackId,
         candidate.score
       ).run();
     }
   }
   ```

**Acceptance Criteria**:
- [ ] Similar feedback found within 2 seconds
- [ ] High-confidence (>0.85) matches stored as suggestions
- [ ] No duplicate suggestions for same pair
- [ ] Workspace isolation enforced

---

### 2.2.3 Duplicate Suggestion API (1.5h)
**Objective**: API endpoints for managing duplicate suggestions

**Steps**:
1. Get duplicate suggestions:
   ```typescript
   // GET /api/v1/feedback/:id/duplicates
   async function handleGetDuplicates(request: Request, env: Env) {
     const { feedbackId } = parseParams(request);
     const feedback = await getFeedbackById(feedbackId, env);
     if (!feedback) return errorResponse('NOT_FOUND', 'Feedback not found', 404);

     await requirePermission(request, env, feedback.workspace_id, 'feedback:moderate');

     const suggestions = await env.DB.prepare(`
       SELECT ds.*, fi.title, fi.description, fi.status, fi.vote_count
       FROM duplicate_suggestions ds
       JOIN feedback_items fi ON ds.target_feedback_id = fi.id
       WHERE ds.source_feedback_id = ? AND ds.status = 'pending'
       ORDER BY ds.similarity_score DESC
     `).bind(feedbackId).all();

     return jsonResponse({ duplicates: suggestions.results });
   }
   ```

2. Merge duplicates:
   ```typescript
   // POST /api/v1/feedback/:id/duplicates/:targetId/merge
   async function handleMergeDuplicates(request: Request, env: Env) {
     const { feedbackId, targetId } = parseParams(request);
     const { keep } = await validateBody(request, z.object({
       keep: z.enum(['source', 'target']).default('target')
     }));

     const { user } = await requirePermission(request, env, workspaceId, 'feedback:moderate');

     // Determine primary and secondary
     const [primary, secondary] = keep === 'target'
       ? [targetId, feedbackId]
       : [feedbackId, targetId];

     await env.DB.batch([
       // Move votes (no double-counting same user)
       env.DB.prepare(`
         INSERT OR IGNORE INTO feedback_votes (id, feedback_id, user_id, weight)
         SELECT ?, ?, user_id, weight FROM feedback_votes WHERE feedback_id = ?
       `).bind(generateId('vote'), primary, secondary),

       // Move comments
       env.DB.prepare(`
         UPDATE feedback_comments SET feedback_id = ? WHERE feedback_id = ?
       `).bind(primary, secondary),

       // Hide secondary with merge reference
       env.DB.prepare(`
         UPDATE feedback_items
         SET is_hidden = 1, merged_into_id = ?, updated_at = datetime('now')
         WHERE id = ?
       `).bind(primary, secondary),

       // Update vote count on primary
       env.DB.prepare(`
         UPDATE feedback_items
         SET vote_count = (SELECT COALESCE(SUM(weight), 0) FROM feedback_votes WHERE feedback_id = ?)
         WHERE id = ?
       `).bind(primary, primary),

       // Mark suggestion as merged
       env.DB.prepare(`
         UPDATE duplicate_suggestions
         SET status = 'merged', reviewed_by = ?, reviewed_at = datetime('now')
         WHERE source_feedback_id = ? AND target_feedback_id = ?
       `).bind(user.id, feedbackId, targetId)
     ]);

     return jsonResponse({ merged_into: primary });
   }
   ```

3. Dismiss duplicate suggestion:
   ```typescript
   // POST /api/v1/feedback/:id/duplicates/:targetId/dismiss
   async function handleDismissDuplicate(request: Request, env: Env) {
     const { feedbackId, targetId } = parseParams(request);
     const { user } = await requirePermission(request, env, workspaceId, 'feedback:moderate');

     await env.DB.prepare(`
       UPDATE duplicate_suggestions
       SET status = 'dismissed', reviewed_by = ?, reviewed_at = datetime('now')
       WHERE source_feedback_id = ? AND target_feedback_id = ?
     `).bind(user.id, feedbackId, targetId).run();

     return jsonResponse({ message: 'Suggestion dismissed' });
   }
   ```

**Acceptance Criteria**:
- [ ] Get suggestions returns pending duplicates
- [ ] Merge combines votes without double-counting
- [ ] Merge moves all comments
- [ ] Dismiss removes from suggestions list
- [ ] Audit trail preserved

---

### 2.2.4 Admin UI for Duplicates (2h)
**Objective**: Interface for reviewing and managing duplicates

**Steps**:
1. Add duplicates section to admin:
   ```typescript
   // GET /api/v1/workspaces/:id/duplicates
   async function handleListWorkspaceDuplicates(request: Request, env: Env) {
     const { workspaceId } = parseParams(request);
     await requirePermission(request, env, workspaceId, 'feedback:moderate');

     const url = new URL(request.url);
     const limit = Math.min(parseInt(url.searchParams.get('limit') || '20'), 50);
     const offset = parseInt(url.searchParams.get('offset') || '0');

     const suggestions = await env.DB.prepare(`
       SELECT
         ds.*,
         sf.title as source_title,
         sf.vote_count as source_votes,
         tf.title as target_title,
         tf.vote_count as target_votes
       FROM duplicate_suggestions ds
       JOIN feedback_items sf ON ds.source_feedback_id = sf.id
       JOIN feedback_items tf ON ds.target_feedback_id = tf.id
       JOIN boards b ON sf.board_id = b.id
       WHERE b.workspace_id = ? AND ds.status = 'pending'
       ORDER BY ds.similarity_score DESC, ds.created_at DESC
       LIMIT ? OFFSET ?
     `).bind(workspaceId, limit, offset).all();

     const total = await env.DB.prepare(`
       SELECT COUNT(*) as count
       FROM duplicate_suggestions ds
       JOIN feedback_items sf ON ds.source_feedback_id = sf.id
       JOIN boards b ON sf.board_id = b.id
       WHERE b.workspace_id = ? AND ds.status = 'pending'
     `).bind(workspaceId).first();

     return jsonResponse({
       suggestions: suggestions.results,
       total: total?.count || 0,
       pagination: { limit, offset }
     });
   }
   ```

2. Bulk actions endpoint:
   ```typescript
   // POST /api/v1/workspaces/:id/duplicates/bulk
   async function handleBulkDuplicateAction(request: Request, env: Env) {
     const { workspaceId } = parseParams(request);
     const { action, suggestion_ids } = await validateBody(request, z.object({
       action: z.enum(['merge', 'dismiss']),
       suggestion_ids: z.array(z.string()).min(1).max(50)
     }));

     await requirePermission(request, env, workspaceId, 'feedback:moderate');

     let processed = 0;
     for (const id of suggestion_ids) {
       // Execute action for each (or batch with transactions)
       if (action === 'dismiss') {
         await dismissDuplicate(id, env);
         processed++;
       }
       // Merge requires more careful handling per-item
     }

     return jsonResponse({ processed, action });
   }
   ```

**Acceptance Criteria**:
- [ ] List all pending duplicates for workspace
- [ ] Side-by-side comparison view data
- [ ] Similarity score displayed
- [ ] Bulk dismiss action works
- [ ] Pagination for large lists

---

### 2.2.5 Batch Processing for Existing Feedback (1h)
**Objective**: Backfill embeddings and detect duplicates for existing data

**Steps**:
1. Create batch embedding script:
   ```typescript
   // src/scripts/batch-embed.ts

   export async function batchEmbedFeedback(
     workspaceId: string,
     env: Env,
     options: { batchSize: number; dryRun: boolean }
   ): Promise<{ processed: number; errors: number }> {
     let processed = 0;
     let errors = 0;
     let offset = 0;

     while (true) {
       // Get unembedded feedback
       const batch = await env.DB.prepare(`
         SELECT fi.id, fi.title, fi.description
         FROM feedback_items fi
         JOIN boards b ON fi.board_id = b.id
         WHERE b.workspace_id = ? AND fi.ai_embedding_id IS NULL
         LIMIT ? OFFSET ?
       `).bind(workspaceId, options.batchSize, offset).all();

       if (batch.results.length === 0) break;

       for (const item of batch.results) {
         try {
           if (!options.dryRun) {
             await processEmbedding(item.id, env);
           }
           processed++;
         } catch (e) {
           console.error(`Failed to embed ${item.id}:`, e);
           errors++;
         }
       }

       offset += options.batchSize;
       console.log(`Progress: ${processed} processed, ${errors} errors`);
     }

     return { processed, errors };
   }
   ```

2. Create duplicate detection batch:
   ```typescript
   export async function batchDetectDuplicates(
     workspaceId: string,
     env: Env
   ): Promise<{ suggestions: number }> {
     let suggestions = 0;

     // Get all embedded feedback
     const items = await env.DB.prepare(`
       SELECT fi.id, fi.ai_embedding_id
       FROM feedback_items fi
       JOIN boards b ON fi.board_id = b.id
       WHERE b.workspace_id = ? AND fi.ai_embedding_id IS NOT NULL
       ORDER BY fi.created_at DESC
     `).bind(workspaceId).all();

     for (const item of items.results) {
       // Get embedding from Vectorize
       const vectors = await env.VECTORIZE.getByIds([item.id]);
       if (!vectors[0]) continue;

       const candidates = await findDuplicates(
         item.id,
         vectors[0].values,
         workspaceId,
         env
       );

       await storeDuplicateSuggestions(item.id, candidates, env);
       suggestions += candidates.filter(c => c.score >= 0.85).length;
     }

     return { suggestions };
   }
   ```

**Acceptance Criteria**:
- [ ] Can process all existing feedback in batches
- [ ] Progress reporting during batch
- [ ] Handles interruption gracefully (can resume)
- [ ] Dry-run mode for testing

---

## Definition of Done
- [ ] All new feedback embedded automatically
- [ ] Duplicates detected on creation
- [ ] Admin can review, merge, or dismiss
- [ ] Batch processing for historical data
- [ ] Merge preserves all votes and comments

## Technical Notes
- Vectorize cosine similarity: 1.0 = identical, 0.0 = unrelated
- 0.85 threshold tested on sample data for low false positives
- Merge is soft-delete (hidden + merged_into_id) for audit
- Consider adding "undo merge" functionality

## Related Files
- `src/lib/ai/deduplication.ts` - Core dedup logic
- `src/lib/ai/processors/embed.ts` - Embedding processor
- `src/routes/duplicates.ts` - API endpoints
- `src/scripts/batch-embed.ts` - Batch processing
