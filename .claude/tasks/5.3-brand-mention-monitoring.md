# Epic 5.3: Brand Mention Monitoring

## Methodology Guidance
**SPECTRA Phase**: Implementation/Integration
**Approach**: Web scraping for brand mentions
**Tools**: Firecrawl API, keyword detection, sentiment analysis

## Wave Context
**Wave**: 5 - Data Ingestion & Multi-Channel
**Priority**: P2 (proactive feedback)
**Dependencies**: Wave 2 (AI pipeline), 5.1 (import infrastructure)
**Estimated Duration**: 8 hours

## Quality Requirements
- Respectful scraping with rate limits
- Accurate brand/keyword matching
- Noise filtering (irrelevant mentions)
- Pain point detection

---

## Tasks

### 5.3.1 Firecrawl Integration (2h)
**Objective**: Set up web scraping infrastructure

**Steps**:
1. Create Firecrawl client:
   ```typescript
   // src/lib/monitoring/firecrawl.ts

   interface FirecrawlConfig {
     api_key: string;
     base_url?: string;
   }

   interface CrawlOptions {
     url: string;
     maxDepth?: number;
     limit?: number;
     includePaths?: string[];
     excludePaths?: string[];
     waitFor?: number;
   }

   interface ScrapeResult {
     success: boolean;
     data?: {
       markdown: string;
       content: string;
       html: string;
       metadata: {
         title: string;
         description: string;
         language: string;
         sourceURL: string;
         statusCode: number;
       };
       links: string[];
     };
     error?: string;
   }

   interface CrawlResult {
     success: boolean;
     jobId?: string;
     data?: ScrapeResult[];
     error?: string;
   }

   export class FirecrawlClient {
     private apiKey: string;
     private baseUrl: string;

     constructor(config: FirecrawlConfig) {
       this.apiKey = config.api_key;
       this.baseUrl = config.base_url || 'https://api.firecrawl.dev/v1';
     }

     private async request(
       endpoint: string,
       method: string = 'GET',
       body?: unknown
     ): Promise<unknown> {
       const response = await fetch(`${this.baseUrl}${endpoint}`, {
         method,
         headers: {
           'Authorization': `Bearer ${this.apiKey}`,
           'Content-Type': 'application/json'
         },
         body: body ? JSON.stringify(body) : undefined
       });

       if (!response.ok) {
         const error = await response.text();
         throw new Error(`Firecrawl API error: ${response.status} - ${error}`);
       }

       return response.json();
     }

     async scrape(url: string): Promise<ScrapeResult> {
       return this.request('/scrape', 'POST', { url }) as Promise<ScrapeResult>;
     }

     async crawl(options: CrawlOptions): Promise<CrawlResult> {
       return this.request('/crawl', 'POST', options) as Promise<CrawlResult>;
     }

     async getCrawlStatus(jobId: string): Promise<CrawlResult> {
       return this.request(`/crawl/${jobId}`) as Promise<CrawlResult>;
     }

     async search(query: string, options?: { limit?: number }): Promise<ScrapeResult[]> {
       const result = await this.request('/search', 'POST', {
         query,
         limit: options?.limit || 10
       }) as { data: ScrapeResult[] };
       return result.data;
     }
   }
   ```

2. Create monitoring job table:
   ```sql
   CREATE TABLE monitoring_jobs (
     id TEXT PRIMARY KEY,
     workspace_id TEXT NOT NULL,
     name TEXT NOT NULL,
     type TEXT NOT NULL,  -- 'brand_mention', 'competitor', 'keyword'
     config TEXT NOT NULL,  -- JSON configuration
     status TEXT DEFAULT 'active',  -- active, paused, disabled
     schedule TEXT,  -- cron expression
     last_run_at TEXT,
     next_run_at TEXT,
     stats TEXT,  -- JSON: {total_found, new_items, errors}
     created_at TEXT DEFAULT (datetime('now')),
     updated_at TEXT DEFAULT (datetime('now')),
     FOREIGN KEY (workspace_id) REFERENCES workspaces(id)
   );

   CREATE TABLE monitoring_results (
     id TEXT PRIMARY KEY,
     job_id TEXT NOT NULL,
     workspace_id TEXT NOT NULL,
     source_url TEXT NOT NULL,
     source_title TEXT,
     content_snippet TEXT,
     matched_keywords TEXT,  -- JSON array
     sentiment_score REAL,
     is_pain_point INTEGER DEFAULT 0,
     feedback_id TEXT,  -- If converted to feedback
     status TEXT DEFAULT 'pending',  -- pending, reviewed, converted, ignored
     found_at TEXT DEFAULT (datetime('now')),
     FOREIGN KEY (job_id) REFERENCES monitoring_jobs(id),
     FOREIGN KEY (workspace_id) REFERENCES workspaces(id),
     FOREIGN KEY (feedback_id) REFERENCES feedback_items(id)
   );

   CREATE INDEX idx_monitoring_results_job ON monitoring_results(job_id, status);
   CREATE INDEX idx_monitoring_results_pain ON monitoring_results(workspace_id, is_pain_point, status);
   ```

3. Create monitoring job API:
   ```typescript
   // POST /api/v1/workspaces/:id/monitoring
   interface CreateMonitoringJobRequest {
     name: string;
     type: 'brand_mention' | 'competitor' | 'keyword';
     config: {
       keywords: string[];
       exclude_keywords?: string[];
       sources?: Array<{
         type: 'url' | 'domain' | 'search';
         value: string;
       }>;
       sentiment_filter?: 'all' | 'negative' | 'neutral_negative';
       pain_point_detection?: boolean;
     };
     schedule?: string;  // Cron expression, e.g., '0 */6 * * *' (every 6 hours)
   }

   async function handleCreateMonitoringJob(request: Request, env: Env): Promise<Response> {
     const { workspaceId } = parseParams(request);
     const input = await validateBody(request, CreateMonitoringJobSchema);

     await requirePermission(request, env, workspaceId, 'monitoring:create');

     const jobId = generateId('mon');

     await env.DB.prepare(`
       INSERT INTO monitoring_jobs (id, workspace_id, name, type, config, schedule)
       VALUES (?, ?, ?, ?, ?, ?)
     `).bind(
       jobId,
       workspaceId,
       input.name,
       input.type,
       JSON.stringify(input.config),
       input.schedule
     ).run();

     // Schedule first run
     if (input.schedule) {
       await env.MONITORING_QUEUE.send({
         type: 'run_monitoring',
         job_id: jobId,
         workspace_id: workspaceId
       });
     }

     return jsonResponse({ id: jobId, status: 'active' }, 201);
   }
   ```

**Acceptance Criteria**:
- [ ] Firecrawl client working
- [ ] Monitoring jobs configurable
- [ ] Scheduled runs working
- [ ] Results stored

---

### 5.3.2 Keyword Configuration (2h)
**Objective**: Flexible keyword matching rules

**Steps**:
1. Create keyword matching engine:
   ```typescript
   // src/lib/monitoring/keywords.ts

   interface KeywordRule {
     term: string;
     type: 'exact' | 'fuzzy' | 'regex' | 'phrase';
     weight?: number;  // 1-10, affects priority
     context?: 'title' | 'body' | 'any';
   }

   interface KeywordConfig {
     include: KeywordRule[];
     exclude?: KeywordRule[];
     min_match_score?: number;  // 0-100
   }

   interface MatchResult {
     matched: boolean;
     score: number;
     matches: Array<{
       keyword: string;
       type: string;
       position: number;
       context: string;
     }>;
   }

   export function matchKeywords(
     content: string,
     title: string,
     config: KeywordConfig
   ): MatchResult {
     const matches: MatchResult['matches'] = [];
     let totalScore = 0;

     const fullText = `${title}\n${content}`.toLowerCase();
     const titleLower = title.toLowerCase();
     const contentLower = content.toLowerCase();

     // Check include keywords
     for (const rule of config.include) {
       const weight = rule.weight || 1;
       const textToSearch = rule.context === 'title' ? titleLower
         : rule.context === 'body' ? contentLower
         : fullText;

       let found = false;
       let position = -1;

       switch (rule.type) {
         case 'exact':
           position = textToSearch.indexOf(rule.term.toLowerCase());
           found = position !== -1;
           break;

         case 'phrase':
           const phraseRegex = new RegExp(`\\b${escapeRegex(rule.term)}\\b`, 'i');
           const phraseMatch = textToSearch.match(phraseRegex);
           found = !!phraseMatch;
           position = phraseMatch?.index ?? -1;
           break;

         case 'fuzzy':
           // Simple fuzzy: check if all words appear within proximity
           const words = rule.term.toLowerCase().split(/\s+/);
           const positions = words.map(w => textToSearch.indexOf(w));
           found = positions.every(p => p !== -1);
           if (found) {
             const maxDist = Math.max(...positions) - Math.min(...positions);
             found = maxDist < 200;  // Words within 200 chars
             position = Math.min(...positions);
           }
           break;

         case 'regex':
           try {
             const regex = new RegExp(rule.term, 'i');
             const regexMatch = textToSearch.match(regex);
             found = !!regexMatch;
             position = regexMatch?.index ?? -1;
           } catch {
             // Invalid regex, skip
           }
           break;
       }

       if (found) {
         totalScore += weight * 10;
         matches.push({
           keyword: rule.term,
           type: rule.type,
           position,
           context: extractContext(fullText, position)
         });
       }
     }

     // Check exclude keywords (negate match)
     if (config.exclude) {
       for (const rule of config.exclude) {
         const textToSearch = rule.context === 'title' ? titleLower
           : rule.context === 'body' ? contentLower
           : fullText;

         if (textToSearch.includes(rule.term.toLowerCase())) {
           return { matched: false, score: 0, matches: [] };
         }
       }
     }

     const minScore = config.min_match_score ?? 10;
     return {
       matched: totalScore >= minScore,
       score: totalScore,
       matches
     };
   }

   function extractContext(text: string, position: number, contextLength: number = 100): string {
     if (position === -1) return '';

     const start = Math.max(0, position - contextLength / 2);
     const end = Math.min(text.length, position + contextLength / 2);

     let context = text.slice(start, end);
     if (start > 0) context = '...' + context;
     if (end < text.length) context = context + '...';

     return context.trim();
   }

   function escapeRegex(str: string): string {
     return str.replace(/[.*+?^${}()|[\]\\]/g, '\\$&');
   }
   ```

2. Create keyword preset templates:
   ```typescript
   // src/lib/monitoring/presets.ts

   export const MONITORING_PRESETS = {
     brand_mention: (brandName: string) => ({
       include: [
         { term: brandName, type: 'phrase' as const, weight: 10 },
         { term: `@${brandName}`, type: 'exact' as const, weight: 8 },
         { term: `#${brandName}`, type: 'exact' as const, weight: 6 }
       ],
       exclude: [
         { term: 'job listing', type: 'phrase' as const },
         { term: 'hiring', type: 'exact' as const }
       ]
     }),

     pain_points: (productName: string) => ({
       include: [
         { term: productName, type: 'phrase' as const, weight: 5 },
         { term: 'frustrated with', type: 'phrase' as const, weight: 10, context: 'body' as const },
         { term: 'hate when', type: 'phrase' as const, weight: 10, context: 'body' as const },
         { term: 'wish it could', type: 'phrase' as const, weight: 8, context: 'body' as const },
         { term: "doesn't work", type: 'phrase' as const, weight: 9, context: 'body' as const },
         { term: 'broken', type: 'exact' as const, weight: 7, context: 'body' as const },
         { term: 'bug', type: 'exact' as const, weight: 6, context: 'body' as const },
         { term: 'missing feature', type: 'phrase' as const, weight: 8, context: 'body' as const }
       ],
       min_match_score: 15
     }),

     feature_requests: (productName: string) => ({
       include: [
         { term: productName, type: 'phrase' as const, weight: 3 },
         { term: 'would be nice if', type: 'phrase' as const, weight: 10 },
         { term: 'feature request', type: 'phrase' as const, weight: 10 },
         { term: 'please add', type: 'phrase' as const, weight: 9 },
         { term: 'wish there was', type: 'phrase' as const, weight: 8 },
         { term: 'need a way to', type: 'phrase' as const, weight: 8 },
         { term: 'should support', type: 'phrase' as const, weight: 7 }
       ],
       min_match_score: 13
     }),

     competitor_mention: (competitorNames: string[]) => ({
       include: competitorNames.map(name => ({
         term: name,
         type: 'phrase' as const,
         weight: 10
       })),
       min_match_score: 10
     })
   };
   ```

**Acceptance Criteria**:
- [ ] Exact/fuzzy/regex matching
- [ ] Exclude patterns working
- [ ] Context extraction accurate
- [ ] Presets easy to use

---

### 5.3.3 Pain Point Detection (2h)
**Objective**: Identify frustration signals

**Steps**:
1. Create pain point classifier:
   ```typescript
   // src/lib/monitoring/pain-points.ts

   interface PainPointSignal {
     type: 'frustration' | 'confusion' | 'bug_report' | 'missing_feature' | 'performance';
     confidence: number;  // 0-1
     indicators: string[];
   }

   const FRUSTRATION_INDICATORS = [
     { pattern: /\b(hate|hating|hated)\b/i, weight: 0.9 },
     { pattern: /\b(frustrated|frustrating|frustration)\b/i, weight: 0.95 },
     { pattern: /\b(annoying|annoyed|annoys)\b/i, weight: 0.8 },
     { pattern: /\b(terrible|awful|horrible)\b/i, weight: 0.85 },
     { pattern: /\b(useless|worthless)\b/i, weight: 0.9 },
     { pattern: /\bwaste of time\b/i, weight: 0.85 },
     { pattern: /\b(broken|doesn't work|not working)\b/i, weight: 0.8 },
     { pattern: /\b(give up|gave up|giving up)\b/i, weight: 0.9 },
     { pattern: /!{2,}/g, weight: 0.3 },  // Multiple exclamation marks
     { pattern: /\b(ugh|argh|grr)\b/i, weight: 0.7 }
   ];

   const CONFUSION_INDICATORS = [
     { pattern: /\b(confused|confusing|confusion)\b/i, weight: 0.9 },
     { pattern: /\b(don't understand|doesn't make sense)\b/i, weight: 0.85 },
     { pattern: /\bhow (do|does|can|to)\b.*\?/i, weight: 0.6 },
     { pattern: /\bwhat (is|does|means)\b.*\?/i, weight: 0.5 },
     { pattern: /\b(unclear|not clear)\b/i, weight: 0.8 },
     { pattern: /\b(lost|stuck)\b/i, weight: 0.6 }
   ];

   const BUG_INDICATORS = [
     { pattern: /\bbug\b/i, weight: 0.9 },
     { pattern: /\b(error|errors)\b/i, weight: 0.7 },
     { pattern: /\b(crash|crashed|crashing)\b/i, weight: 0.95 },
     { pattern: /\b(glitch|glitchy)\b/i, weight: 0.85 },
     { pattern: /\b(broken|breaks)\b/i, weight: 0.75 },
     { pattern: /\b(issue|problem)\b/i, weight: 0.5 }
   ];

   const FEATURE_REQUEST_INDICATORS = [
     { pattern: /\b(wish|wishing)\b.*\b(could|would|had)\b/i, weight: 0.9 },
     { pattern: /\bwould be (nice|great|awesome) if\b/i, weight: 0.95 },
     { pattern: /\bplease (add|include|support)\b/i, weight: 0.9 },
     { pattern: /\bfeature request\b/i, weight: 1.0 },
     { pattern: /\b(need|needs) (a|to|support for)\b/i, weight: 0.7 },
     { pattern: /\bmissing\b/i, weight: 0.6 }
   ];

   const PERFORMANCE_INDICATORS = [
     { pattern: /\b(slow|slower|slowest)\b/i, weight: 0.9 },
     { pattern: /\b(lag|laggy|lagging)\b/i, weight: 0.9 },
     { pattern: /\btakes (forever|too long)\b/i, weight: 0.85 },
     { pattern: /\b(performance|speed)\b.*\b(issue|problem|bad)\b/i, weight: 0.9 },
     { pattern: /\b(loading|loads)\b.*\b(slow|forever)\b/i, weight: 0.85 }
   ];

   export function detectPainPoints(content: string): PainPointSignal[] {
     const signals: PainPointSignal[] = [];

     const categories = [
       { type: 'frustration' as const, indicators: FRUSTRATION_INDICATORS },
       { type: 'confusion' as const, indicators: CONFUSION_INDICATORS },
       { type: 'bug_report' as const, indicators: BUG_INDICATORS },
       { type: 'missing_feature' as const, indicators: FEATURE_REQUEST_INDICATORS },
       { type: 'performance' as const, indicators: PERFORMANCE_INDICATORS }
     ];

     for (const category of categories) {
       const matchedIndicators: string[] = [];
       let totalWeight = 0;
       let maxWeight = 0;

       for (const indicator of category.indicators) {
         const matches = content.match(indicator.pattern);
         if (matches) {
           matchedIndicators.push(matches[0]);
           totalWeight += indicator.weight;
           maxWeight = Math.max(maxWeight, indicator.weight);
         }
       }

       if (matchedIndicators.length > 0) {
         // Confidence based on match count and weight
         const confidence = Math.min(
           0.5 * maxWeight + 0.5 * (totalWeight / category.indicators.length),
           1.0
         );

         signals.push({
           type: category.type,
           confidence,
           indicators: matchedIndicators
         });
       }
     }

     return signals.sort((a, b) => b.confidence - a.confidence);
   }

   export function isPainPoint(content: string, threshold: number = 0.6): boolean {
     const signals = detectPainPoints(content);
     return signals.some(s => s.confidence >= threshold);
   }
   ```

2. Integrate with AI for deeper analysis:
   ```typescript
   // src/lib/monitoring/ai-analysis.ts

   export async function analyzePainPointWithAI(
     env: Env,
     content: string,
     title: string,
     signals: PainPointSignal[]
   ): Promise<{
     is_pain_point: boolean;
     pain_type: string | null;
     severity: 'low' | 'medium' | 'high' | 'critical';
     suggested_category: string | null;
     summary: string;
   }> {
     const prompt = `Analyze this user feedback for pain points and frustration signals.

Title: ${title}

Content:
${content.slice(0, 1500)}

Detected signals: ${signals.map(s => `${s.type} (${Math.round(s.confidence * 100)}%)`).join(', ')}

Respond in JSON format:
{
  "is_pain_point": boolean,
  "pain_type": "bug" | "ux" | "performance" | "missing_feature" | "documentation" | null,
  "severity": "low" | "medium" | "high" | "critical",
  "suggested_category": string or null,
  "summary": "one sentence summary of the issue"
}`;

     const response = await env.AI.run('@cf/meta/llama-3.1-8b-instruct', {
       messages: [
         { role: 'system', content: 'You are a product feedback analyst. Analyze text for pain points and respond only in valid JSON.' },
         { role: 'user', content: prompt }
       ],
       max_tokens: 200
     });

     try {
       return JSON.parse(response.response);
     } catch {
       // Fallback if AI response isn't valid JSON
       return {
         is_pain_point: signals.some(s => s.confidence >= 0.6),
         pain_type: signals[0]?.type === 'bug_report' ? 'bug'
           : signals[0]?.type === 'missing_feature' ? 'missing_feature'
           : signals[0]?.type === 'performance' ? 'performance'
           : null,
         severity: 'medium',
         suggested_category: null,
         summary: `Detected ${signals[0]?.type || 'feedback'} with ${Math.round((signals[0]?.confidence || 0) * 100)}% confidence`
       };
     }
   }
   ```

**Acceptance Criteria**:
- [ ] Pattern matching identifies frustration
- [ ] Multiple signal types detected
- [ ] AI analysis enhances accuracy
- [ ] Severity correctly assessed

---

### 5.3.4 Mention Processing Queue (2h)
**Objective**: Process mentions asynchronously

**Steps**:
1. Create monitoring queue handler:
   ```typescript
   // src/queues/monitoring-consumer.ts

   export async function handleMonitoringQueue(
     batch: MessageBatch,
     env: Env
   ): Promise<void> {
     for (const message of batch.messages) {
       const { type, job_id, workspace_id } = message.body;

       try {
         switch (type) {
           case 'run_monitoring':
             await runMonitoringJob(env, job_id, workspace_id);
             break;
           case 'process_result':
             await processMonitoringResult(env, message.body);
             break;
         }
         message.ack();
       } catch (error) {
         console.error(`Monitoring error for job ${job_id}:`, error);
         message.retry();
       }
     }
   }

   async function runMonitoringJob(
     env: Env,
     jobId: string,
     workspaceId: string
   ): Promise<void> {
     const job = await env.DB.prepare(`
       SELECT * FROM monitoring_jobs WHERE id = ? AND status = 'active'
     `).bind(jobId).first();

     if (!job) return;

     const config = JSON.parse(job.config as string);
     const firecrawl = new FirecrawlClient({ api_key: env.FIRECRAWL_API_KEY });

     let results: ScrapeResult[] = [];

     // Process each source
     for (const source of config.sources || []) {
       switch (source.type) {
         case 'search':
           // Search web for keywords
           for (const keyword of config.keywords) {
             const query = `"${keyword}" ${source.value || ''}`.trim();
             const searchResults = await firecrawl.search(query, { limit: 20 });
             results.push(...searchResults);
             await new Promise(r => setTimeout(r, 1000));  // Rate limit
           }
           break;

         case 'url':
           // Scrape specific URL
           const scrapeResult = await firecrawl.scrape(source.value);
           if (scrapeResult.success) {
             results.push(scrapeResult);
           }
           break;

         case 'domain':
           // Crawl domain
           const crawlResult = await firecrawl.crawl({
             url: source.value,
             maxDepth: 2,
             limit: 50
           });
           if (crawlResult.data) {
             results.push(...crawlResult.data);
           }
           break;
       }
     }

     // Queue each result for processing
     for (const result of results) {
       if (!result.data) continue;

       await env.MONITORING_QUEUE.send({
         type: 'process_result',
         job_id: jobId,
         workspace_id: workspaceId,
         result: {
           url: result.data.metadata.sourceURL,
           title: result.data.metadata.title,
           content: result.data.content
         },
         config
       });
     }

     // Update job stats
     await env.DB.prepare(`
       UPDATE monitoring_jobs
       SET last_run_at = datetime('now'),
           stats = json_patch(COALESCE(stats, '{}'), ?)
       WHERE id = ?
     `).bind(
       JSON.stringify({ last_results_count: results.length }),
       jobId
     ).run();
   }

   async function processMonitoringResult(
     env: Env,
     message: {
       job_id: string;
       workspace_id: string;
       result: { url: string; title: string; content: string };
       config: MonitoringConfig;
     }
   ): Promise<void> {
     const { job_id, workspace_id, result, config } = message;

     // Check if already processed (by URL)
     const existing = await env.DB.prepare(`
       SELECT id FROM monitoring_results WHERE job_id = ? AND source_url = ?
     `).bind(job_id, result.url).first();

     if (existing) return;

     // Match keywords
     const keywordConfig = {
       include: config.keywords.map(k => ({
         term: k,
         type: 'phrase' as const,
         weight: 5
       })),
       exclude: config.exclude_keywords?.map(k => ({
         term: k,
         type: 'exact' as const
       }))
     };

     const match = matchKeywords(result.content, result.title, keywordConfig);
     if (!match.matched) return;

     // Detect pain points
     const painPointSignals = detectPainPoints(result.content);
     const isPainPoint = painPointSignals.some(s => s.confidence >= 0.6);

     // Analyze sentiment
     let sentimentScore = 0.5;  // Neutral default
     if (isPainPoint || config.pain_point_detection) {
       const aiAnalysis = await analyzePainPointWithAI(
         env,
         result.content,
         result.title,
         painPointSignals
       );
       sentimentScore = aiAnalysis.severity === 'critical' ? 0.1
         : aiAnalysis.severity === 'high' ? 0.25
         : aiAnalysis.severity === 'medium' ? 0.4
         : 0.5;
     }

     // Store result
     await env.DB.prepare(`
       INSERT INTO monitoring_results (
         id, job_id, workspace_id, source_url, source_title,
         content_snippet, matched_keywords, sentiment_score, is_pain_point
       ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
     `).bind(
       generateId('mres'),
       job_id,
       workspace_id,
       result.url,
       result.title,
       result.content.slice(0, 500),
       JSON.stringify(match.matches.map(m => m.keyword)),
       sentimentScore,
       isPainPoint ? 1 : 0
     ).run();
   }
   ```

2. Create mention review API:
   ```typescript
   // GET /api/v1/workspaces/:id/monitoring/results
   async function handleListMonitoringResults(request: Request, env: Env): Promise<Response> {
     const { workspaceId } = parseParams(request);
     const url = new URL(request.url);
     const status = url.searchParams.get('status') || 'pending';
     const painPointsOnly = url.searchParams.get('pain_points') === 'true';

     await requirePermission(request, env, workspaceId, 'monitoring:read');

     let query = `
       SELECT mr.*, mj.name as job_name
       FROM monitoring_results mr
       JOIN monitoring_jobs mj ON mr.job_id = mj.id
       WHERE mr.workspace_id = ? AND mr.status = ?
     `;

     if (painPointsOnly) {
       query += ' AND mr.is_pain_point = 1';
     }

     query += ' ORDER BY mr.found_at DESC LIMIT 50';

     const results = await env.DB.prepare(query)
       .bind(workspaceId, status)
       .all();

     return jsonResponse({
       results: results.results.map(r => ({
         id: r.id,
         job_name: r.job_name,
         source_url: r.source_url,
         source_title: r.source_title,
         snippet: r.content_snippet,
         keywords: JSON.parse(r.matched_keywords as string),
         sentiment: r.sentiment_score,
         is_pain_point: r.is_pain_point === 1,
         status: r.status,
         found_at: r.found_at
       }))
     });
   }

   // POST /api/v1/workspaces/:id/monitoring/results/:resultId/convert
   async function handleConvertToFeedback(request: Request, env: Env): Promise<Response> {
     const { workspaceId, resultId } = parseParams(request);
     const input = await validateBody(request, z.object({
       board_id: z.string(),
       title: z.string().optional(),
       additional_context: z.string().optional()
     }));

     await requirePermission(request, env, workspaceId, 'feedback:create');

     const result = await env.DB.prepare(`
       SELECT * FROM monitoring_results WHERE id = ? AND workspace_id = ?
     `).bind(resultId, workspaceId).first();

     if (!result) {
       return errorResponse('NOT_FOUND', 'Result not found', 404);
     }

     // Create feedback item
     const feedbackId = generateId('fb');
     await env.DB.prepare(`
       INSERT INTO feedback_items (
         id, board_id, title, description,
         source_type, source_url, source_metadata,
         moderation_state, is_hidden
       ) VALUES (?, ?, ?, ?, ?, ?, ?, 'approved', 0)
     `).bind(
       feedbackId,
       input.board_id,
       input.title || result.source_title,
       `${result.content_snippet}\n\n${input.additional_context || ''}\n\nSource: ${result.source_url}`,
       'web_scrape',
       result.source_url,
       JSON.stringify({
         keywords: result.matched_keywords,
         sentiment: result.sentiment_score,
         is_pain_point: result.is_pain_point
       })
     ).run();

     // Update result status
     await env.DB.prepare(`
       UPDATE monitoring_results SET status = 'converted', feedback_id = ?
       WHERE id = ?
     `).bind(feedbackId, resultId).run();

     // Queue for AI processing
     await env.AI_QUEUE.send({
       type: 'process_feedback',
       feedback_id: feedbackId,
       workspace_id: workspaceId
     });

     return jsonResponse({ feedback_id: feedbackId }, 201);
   }
   ```

**Acceptance Criteria**:
- [ ] Async processing handles volume
- [ ] Results stored and reviewable
- [ ] Convert to feedback working
- [ ] Rate limits respected

---

## Definition of Done
- [ ] Firecrawl integration working
- [ ] Keyword matching accurate
- [ ] Pain points detected
- [ ] Review workflow complete
- [ ] No excessive API calls

## Technical Notes
- Firecrawl rate limit: 100 req/min
- Store snippets, not full content
- Schedule jobs during off-peak
- Cache results to avoid re-scraping

## Related Files
- `src/lib/monitoring/firecrawl.ts` - Firecrawl client
- `src/lib/monitoring/keywords.ts` - Keyword matching
- `src/lib/monitoring/pain-points.ts` - Pain detection
- `src/queues/monitoring-consumer.ts` - Queue handler
