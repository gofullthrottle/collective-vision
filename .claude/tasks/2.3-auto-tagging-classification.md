# Epic 2.3: Auto-Tagging & Intent Classification

## Methodology Guidance
**SPECTRA Phase**: Implementation/AI Feature
**Approach**: LLM-powered automatic categorization of feedback
**Tools**: Claude API, structured prompts, tag taxonomy

## Wave Context
**Wave**: 2 - AI Infrastructure + P0 Capabilities
**Priority**: P0 (reduces manual triage effort)
**Dependencies**: Epic 2.1 (LLM integration)
**Estimated Duration**: 8 hours

## Quality Requirements
- Classification accuracy 85%+ (measured by admin corrections)
- AI tags visually distinct from manual tags
- Manual overrides always preserved
- Tag corrections tracked for model improvement

---

## Tasks

### 2.3.1 Tag Taxonomy Definition (1h)
**Objective**: Define standard and custom tag categories

**Steps**:
1. Define default type tags:
   ```typescript
   // src/lib/ai/taxonomy.ts

   export const DEFAULT_TYPE_TAGS = [
     { slug: 'bug', name: 'Bug', description: 'Something is broken', color: '#EF4444' },
     { slug: 'feature_request', name: 'Feature Request', description: 'New functionality', color: '#8B5CF6' },
     { slug: 'improvement', name: 'Improvement', description: 'Enhancement to existing', color: '#3B82F6' },
     { slug: 'question', name: 'Question', description: 'User needs help', color: '#F59E0B' },
     { slug: 'praise', name: 'Praise', description: 'Positive feedback', color: '#10B981' },
     { slug: 'complaint', name: 'Complaint', description: 'Negative but not bug', color: '#6B7280' }
   ] as const;

   export const DEFAULT_URGENCY_TAGS = [
     { slug: 'urgent', name: 'Urgent', description: 'Blocking work', color: '#DC2626' },
     { slug: 'critical', name: 'Critical', description: 'Major impact', color: '#EA580C' }
   ] as const;

   export type FeedbackType = typeof DEFAULT_TYPE_TAGS[number]['slug'];
   export type UrgencyLevel = 'normal' | 'urgent' | 'critical';
   ```

2. Add AI tag marker to database:
   ```sql
   -- Mark tags as auto-generated
   ALTER TABLE feedback_tags ADD COLUMN is_ai_tag INTEGER DEFAULT 0;
   ALTER TABLE feedback_tags ADD COLUMN is_system_tag INTEGER DEFAULT 0;

   -- Track tag application source
   ALTER TABLE feedback_item_tags ADD COLUMN source TEXT DEFAULT 'manual';
   -- source: 'manual' | 'ai' | 'import'

   ALTER TABLE feedback_item_tags ADD COLUMN confidence REAL;
   ```

3. Seed default tags on workspace creation:
   ```typescript
   export async function seedDefaultTags(
     workspaceId: string,
     env: Env
   ): Promise<void> {
     const allTags = [...DEFAULT_TYPE_TAGS, ...DEFAULT_URGENCY_TAGS];

     for (const tag of allTags) {
       await env.DB.prepare(`
         INSERT OR IGNORE INTO feedback_tags
           (id, workspace_id, slug, name, description, color, is_system_tag)
         VALUES (?, ?, ?, ?, ?, ?, 1)
       `).bind(
         generateId('tag'),
         workspaceId,
         tag.slug,
         tag.name,
         tag.description,
         tag.color
       ).run();
     }
   }
   ```

**Acceptance Criteria**:
- [ ] Default type tags defined (6 types)
- [ ] Urgency tags defined (2 levels)
- [ ] AI vs manual tag distinction in schema
- [ ] System tags seeded on workspace creation

---

### 2.3.2 Classification Prompt Engineering (2h)
**Objective**: Create accurate classification prompts

**Steps**:
1. Create classification prompt template:
   ```typescript
   // src/lib/ai/prompts/classification.ts

   export const CLASSIFICATION_PROMPT = `You are a feedback classifier for a product feedback system.

   Analyze this user feedback and classify it accurately.

   ## Feedback Types
   - bug: Something is broken or not working as expected
   - feature_request: User wants new functionality that doesn't exist
   - improvement: Enhancement to existing functionality
   - question: User needs help or clarification
   - praise: Positive feedback about the product
   - complaint: Negative feedback that isn't a specific bug

   ## Urgency Levels
   - normal: Standard priority
   - urgent: Blocking user's work, needs quick attention
   - critical: Major business impact, affecting many users

   ## Urgency Keywords
   Look for: "broken", "urgent", "blocking", "can't work", "critical", "ASAP", "immediately", "production", "down"

   ## Feedback to Classify
   Title: {title}
   Description: {description}

   ## Response Format
   Return ONLY valid JSON, no markdown:
   {
     "type": "bug|feature_request|improvement|question|praise|complaint",
     "urgency": "normal|urgent|critical",
     "product_area": "inferred area (e.g., 'authentication', 'dashboard', 'api') or null",
     "confidence": 0.0-1.0,
     "reasoning": "brief 1-sentence explanation"
   }`;

   export function buildClassificationPrompt(title: string, description: string): string {
     return CLASSIFICATION_PROMPT
       .replace('{title}', title.substring(0, 500))
       .replace('{description}', (description || 'No description provided').substring(0, 2000));
   }
   ```

2. Create validation schema:
   ```typescript
   import { z } from 'zod';

   export const ClassificationResultSchema = z.object({
     type: z.enum(['bug', 'feature_request', 'improvement', 'question', 'praise', 'complaint']),
     urgency: z.enum(['normal', 'urgent', 'critical']),
     product_area: z.string().nullable(),
     confidence: z.number().min(0).max(1),
     reasoning: z.string()
   });

   export type ClassificationResult = z.infer<typeof ClassificationResultSchema>;
   ```

3. Test prompt on sample feedback:
   ```typescript
   const TEST_CASES = [
     {
       title: "App crashes when I try to upload large files",
       description: "Every time I try to upload a file over 10MB, the app freezes and I have to reload.",
       expected: { type: 'bug', urgency: 'normal' }
     },
     {
       title: "URGENT: Production is down!!!",
       description: "Our entire team can't access the dashboard. This is blocking our work.",
       expected: { type: 'bug', urgency: 'critical' }
     },
     {
       title: "Would love dark mode",
       description: "It would be great to have a dark mode option for late night work.",
       expected: { type: 'feature_request', urgency: 'normal' }
     }
   ];
   ```

**Acceptance Criteria**:
- [ ] Prompt handles all feedback types
- [ ] Urgency keywords detected
- [ ] Product area inference works
- [ ] 90%+ accuracy on test cases

---

### 2.3.3 Auto-Tag on Creation (2h)
**Objective**: Apply AI classification to new feedback

**Steps**:
1. Create classification processor:
   ```typescript
   // src/lib/ai/processors/classify.ts

   export async function processClassification(
     feedbackId: string,
     env: Env
   ): Promise<void> {
     const feedback = await getFeedbackById(feedbackId, env);
     if (!feedback) throw new Error('Feedback not found');

     // Call LLM for classification
     const prompt = buildClassificationPrompt(feedback.title, feedback.description);
     const result = await callClaudeAPI(prompt, env);

     // Parse and validate response
     let classification: ClassificationResult;
     try {
       const parsed = JSON.parse(result);
       classification = ClassificationResultSchema.parse(parsed);
     } catch (e) {
       console.error('Failed to parse classification:', e);
       return; // Skip tagging on parse error
     }

     // Apply tags
     await applyClassificationTags(feedbackId, classification, env);

     // Store classification metadata
     await env.DB.prepare(`
       UPDATE feedback_items
       SET
         ai_classification = ?,
         ai_confidence = ?,
         updated_at = datetime('now')
       WHERE id = ?
     `).bind(
       JSON.stringify(classification),
       classification.confidence,
       feedbackId
     ).run();

     // Track usage
     await incrementUsage(env.DB, feedback.workspace_id, 'llm_calls');
   }
   ```

2. Apply tags from classification:
   ```typescript
   async function applyClassificationTags(
     feedbackId: string,
     classification: ClassificationResult,
     env: Env
   ): Promise<void> {
     const feedback = await getFeedbackById(feedbackId, env);
     const workspace = await getWorkspaceForFeedback(feedbackId, env);

     // Find or create type tag
     const typeTag = await findOrCreateTag(
       workspace.id,
       classification.type,
       env
     );

     // Apply type tag
     await env.DB.prepare(`
       INSERT OR IGNORE INTO feedback_item_tags
         (id, feedback_id, tag_id, source, confidence)
       VALUES (?, ?, ?, 'ai', ?)
     `).bind(
       generateId('fit'),
       feedbackId,
       typeTag.id,
       classification.confidence
     ).run();

     // Apply urgency tag if not normal
     if (classification.urgency !== 'normal') {
       const urgencyTag = await findOrCreateTag(
         workspace.id,
         classification.urgency,
         env
       );

       await env.DB.prepare(`
         INSERT OR IGNORE INTO feedback_item_tags
           (id, feedback_id, tag_id, source, confidence)
         VALUES (?, ?, ?, 'ai', ?)
       `).bind(
         generateId('fit'),
         feedbackId,
         urgencyTag.id,
         classification.confidence
       ).run();
     }

     // Create product area tag if inferred
     if (classification.product_area) {
       const areaTag = await findOrCreateTag(
         workspace.id,
         slugify(classification.product_area),
         env,
         { name: classification.product_area, is_ai_tag: true }
       );

       await env.DB.prepare(`
         INSERT OR IGNORE INTO feedback_item_tags
           (id, feedback_id, tag_id, source, confidence)
         VALUES (?, ?, ?, 'ai', ?)
       `).bind(
         generateId('fit'),
         feedbackId,
         areaTag.id,
         classification.confidence
       ).run();
     }
   }
   ```

3. Add classification columns to feedback_items:
   ```sql
   ALTER TABLE feedback_items ADD COLUMN ai_classification TEXT;
   ALTER TABLE feedback_items ADD COLUMN ai_confidence REAL;
   ```

**Acceptance Criteria**:
- [ ] New feedback auto-tagged within 30 seconds
- [ ] Type tag always applied
- [ ] Urgency tag applied when detected
- [ ] Product area tag created when inferred
- [ ] AI tags marked with source='ai'

---

### 2.3.4 Tag Override UI (1.5h)
**Objective**: Allow admins to correct AI tags

**Steps**:
1. Create tag correction endpoint:
   ```typescript
   // PATCH /api/v1/feedback/:id/tags
   async function handleUpdateFeedbackTags(request: Request, env: Env) {
     const { feedbackId } = parseParams(request);
     const { add_tags, remove_tags } = await validateBody(request, z.object({
       add_tags: z.array(z.string()).optional(),
       remove_tags: z.array(z.string()).optional()
     }));

     const { user } = await requirePermission(request, env, workspaceId, 'feedback:moderate');

     // Remove tags
     if (remove_tags?.length) {
       for (const tagId of remove_tags) {
         // Track AI tag removal for accuracy metrics
         const existing = await env.DB.prepare(`
           SELECT source FROM feedback_item_tags
           WHERE feedback_id = ? AND tag_id = ?
         `).bind(feedbackId, tagId).first();

         if (existing?.source === 'ai') {
           await trackTagCorrection(feedbackId, tagId, 'removed', user.id, env);
         }

         await env.DB.prepare(`
           DELETE FROM feedback_item_tags WHERE feedback_id = ? AND tag_id = ?
         `).bind(feedbackId, tagId).run();
       }
     }

     // Add tags (manual source)
     if (add_tags?.length) {
       for (const tagId of add_tags) {
         await env.DB.prepare(`
           INSERT OR REPLACE INTO feedback_item_tags
             (id, feedback_id, tag_id, source)
           VALUES (?, ?, ?, 'manual')
         `).bind(generateId('fit'), feedbackId, tagId).run();
       }
     }

     return jsonResponse({ message: 'Tags updated' });
   }
   ```

2. Track tag corrections for accuracy:
   ```sql
   CREATE TABLE tag_corrections (
     id TEXT PRIMARY KEY,
     feedback_id TEXT NOT NULL,
     original_tag_id TEXT NOT NULL,
     action TEXT NOT NULL,  -- 'removed' or 'replaced'
     replacement_tag_id TEXT,
     corrected_by TEXT NOT NULL,
     created_at TEXT DEFAULT (datetime('now')),
     FOREIGN KEY (feedback_id) REFERENCES feedback_items(id),
     FOREIGN KEY (original_tag_id) REFERENCES feedback_tags(id),
     FOREIGN KEY (corrected_by) REFERENCES users(id)
   );
   ```

3. Get tag accuracy metrics:
   ```typescript
   // GET /api/v1/workspaces/:id/ai/tag-accuracy
   async function handleGetTagAccuracy(request: Request, env: Env) {
     const { workspaceId } = parseParams(request);
     await requirePermission(request, env, workspaceId, 'analytics:view');

     const stats = await env.DB.prepare(`
       SELECT
         COUNT(DISTINCT fit.feedback_id) as total_ai_tagged,
         COUNT(DISTINCT tc.feedback_id) as total_corrected,
         (1.0 - CAST(COUNT(DISTINCT tc.feedback_id) AS REAL) /
          NULLIF(COUNT(DISTINCT fit.feedback_id), 0)) * 100 as accuracy_rate
       FROM feedback_item_tags fit
       JOIN feedback_items fi ON fit.feedback_id = fi.id
       JOIN boards b ON fi.board_id = b.id
       LEFT JOIN tag_corrections tc ON fit.feedback_id = tc.feedback_id
       WHERE b.workspace_id = ? AND fit.source = 'ai'
     `).bind(workspaceId).first();

     return jsonResponse({
       total_ai_tagged: stats?.total_ai_tagged || 0,
       total_corrected: stats?.total_corrected || 0,
       accuracy_rate: stats?.accuracy_rate?.toFixed(1) || '100.0'
     });
   }
   ```

**Acceptance Criteria**:
- [ ] Admins can add/remove tags
- [ ] AI tag corrections tracked
- [ ] Accuracy metrics calculated
- [ ] Manual tags never overwritten by AI

---

### 2.3.5 Batch Classification for Existing (1.5h)
**Objective**: Classify historical untagged feedback

**Steps**:
1. Create batch classification script:
   ```typescript
   // src/scripts/batch-classify.ts

   interface BatchOptions {
     workspaceId: string;
     batchSize: number;
     dryRun: boolean;
     maxItems?: number;
   }

   export async function batchClassifyFeedback(
     options: BatchOptions,
     env: Env
   ): Promise<{ processed: number; errors: number; cost: number }> {
     let processed = 0;
     let errors = 0;
     let offset = 0;

     // Estimate cost first
     const totalUntagged = await env.DB.prepare(`
       SELECT COUNT(*) as count
       FROM feedback_items fi
       JOIN boards b ON fi.board_id = b.id
       LEFT JOIN feedback_item_tags fit ON fi.id = fit.feedback_id AND fit.source = 'ai'
       WHERE b.workspace_id = ? AND fit.id IS NULL
     `).bind(options.workspaceId).first();

     const estimatedCost = (totalUntagged?.count || 0) * 0.001; // ~$0.001 per classification
     console.log(`Estimated cost: $${estimatedCost.toFixed(2)} for ${totalUntagged?.count} items`);

     if (options.dryRun) {
       return { processed: 0, errors: 0, cost: estimatedCost };
     }

     while (true) {
       if (options.maxItems && processed >= options.maxItems) break;

       const batch = await env.DB.prepare(`
         SELECT fi.id, fi.title, fi.description
         FROM feedback_items fi
         JOIN boards b ON fi.board_id = b.id
         LEFT JOIN feedback_item_tags fit ON fi.id = fit.feedback_id AND fit.source = 'ai'
         WHERE b.workspace_id = ? AND fit.id IS NULL
         LIMIT ? OFFSET ?
       `).bind(options.workspaceId, options.batchSize, offset).all();

       if (batch.results.length === 0) break;

       for (const item of batch.results) {
         try {
           await processClassification(item.id, env);
           processed++;

           // Rate limit to avoid API throttling
           await new Promise(r => setTimeout(r, 200));
         } catch (e) {
           console.error(`Failed to classify ${item.id}:`, e);
           errors++;
         }
       }

       offset += options.batchSize;
       console.log(`Progress: ${processed}/${totalUntagged?.count}`);
     }

     return { processed, errors, cost: processed * 0.001 };
   }
   ```

2. Add admin endpoint for batch trigger:
   ```typescript
   // POST /api/v1/workspaces/:id/ai/batch-classify
   async function handleBatchClassify(request: Request, env: Env) {
     const { workspaceId } = parseParams(request);
     const { dry_run, max_items } = await validateBody(request, z.object({
       dry_run: z.boolean().default(true),
       max_items: z.number().optional()
     }));

     await requirePermission(request, env, workspaceId, 'workspace:settings');

     if (dry_run) {
       const estimate = await batchClassifyFeedback({
         workspaceId, batchSize: 10, dryRun: true
       }, env);
       return jsonResponse({ estimate });
     }

     // Queue async job for actual processing
     await env.AI_QUEUE.send({
       type: 'batch_classify',
       workspaceId,
       maxItems: max_items
     });

     return jsonResponse({ message: 'Batch classification queued' });
   }
   ```

**Acceptance Criteria**:
- [ ] Can classify all untagged historical feedback
- [ ] Cost estimate before running
- [ ] Progress tracking during batch
- [ ] Rate limiting to avoid API throttling
- [ ] Resume capability after interruption

---

## Definition of Done
- [ ] Default tag taxonomy seeded
- [ ] Classification prompt achieving 85%+ accuracy
- [ ] New feedback auto-tagged on creation
- [ ] Admin can correct AI tags
- [ ] Accuracy metrics tracked
- [ ] Batch processing for historical data

## Technical Notes
- Claude 3.5 Haiku: ~$0.001 per classification
- Rate limit: 5 requests/second to Claude API
- Cache tag lookups in KV for performance
- Consider fine-tuning prompt based on corrections

## Related Files
- `src/lib/ai/taxonomy.ts` - Tag definitions
- `src/lib/ai/prompts/classification.ts` - LLM prompts
- `src/lib/ai/processors/classify.ts` - Classification processor
- `src/routes/tags.ts` - Tag management endpoints
- `src/scripts/batch-classify.ts` - Batch processing
